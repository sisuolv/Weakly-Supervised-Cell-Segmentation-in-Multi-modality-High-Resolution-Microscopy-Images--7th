{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c5ed8c27-0e3f-400a-8dfd-416939580e8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import os\n",
    "import glob\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "import random\n",
    "import matplotlib.pyplot as plt\n",
    "import json\n",
    "import shutil"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "14a860c0-74e0-4b84-b59a-57e55a2f629d",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_path = './inputs'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "87b23dc1-be79-4f50-9d86-c8944496f0fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_images = glob.glob(os.path.join(input_path, '*.*'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9bc4339a-629b-40da-937c-e4bce8b8c7a6",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3/3 [00:04<00:00,  1.64s/it]\n"
     ]
    }
   ],
   "source": [
    "patch_size = 1000\n",
    "stride = 500\n",
    "\n",
    "if not os.path.isdir('./patched_cache'):\n",
    "    os.makedirs('./patched_cache')\n",
    "else:\n",
    "    #os.removedirs('./patched_cache/')\n",
    "    shutil.rmtree('./patched_cache/', ignore_errors=True)\n",
    "    os.makedirs('./patched_cache')\n",
    "    \n",
    "for img_path in tqdm(all_images):\n",
    "\n",
    "    img = cv2.imread(img_path, cv2.IMREAD_UNCHANGED)\n",
    "    img += img.min()\n",
    "    img = img/(img.max()/255.)\n",
    "    if len(img.shape) == 2:\n",
    "        img = np.stack([img]*3, -1)\n",
    "        #print('gray')\n",
    "    img = img.astype('uint8')\n",
    "    shape = img.shape\n",
    "    if min(shape[:2]) > patch_size:\n",
    "        \n",
    "        x_count = shape[1]//stride\n",
    "        y_count = shape[0]//stride\n",
    "        \n",
    "        for x_id in range(x_count):\n",
    "            for y_id in range(y_count):\n",
    "                \n",
    "                if x_id == x_count - 1:\n",
    "                    xmin, xmax = shape[1]-patch_size, shape[1]\n",
    "                    #print(xmin, xmax)\n",
    "                else:\n",
    "                    xmin, xmax = x_id*stride, x_id*stride + patch_size\n",
    "                if y_id == y_count - 1:\n",
    "                    ymin, ymax = shape[0]-patch_size, shape[0]\n",
    "                    #print(ymin, ymax)\n",
    "                else:\n",
    "                    ymin, ymax = y_id*stride, y_id*stride + patch_size\n",
    "  \n",
    "                cv2.imwrite('{}&{}&{}.png'.format('patched_cache/'+img_path.split('/')[-1].split('.')[0], xmin, ymin), img[ymin:ymax, xmin:xmax])\n",
    "     \n",
    "    else:\n",
    "        cv2.imwrite('{}${}.png'.format('patched_cache/'+img_path.split('/')[-1].split('.')[0], 0), img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "06b618e5-cda0-4e1e-8f53-ab3e41601ed8",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mexport: \u001b[0mdata=data/coco128.yaml, weights=['runs/fold_4.pt', 'runs/fold_3.pt', 'runs/fold_2.pt', 'runs/fold_1.pt', 'runs/fold_0.pt'], imgsz=[1280], batch_size=1, device=0, half=True, inplace=False, keras=False, optimize=False, int8=False, dynamic=False, simplify=False, opset=12, verbose=False, workspace=4, nms=False, agnostic_nms=False, topk_per_class=100, topk_all=100, iou_thres=0.5, conf_thres=0.4, include=['engine']\n",
      "YOLOv5 ðŸš€ v6.2-189-g2f1eb21 Python-3.9.13 torch-1.12.1 CUDA:0 (Quadro RTX 5000, 16125MiB)\n",
      "\n",
      "Fusing layers... \n",
      "Model summary: 206 layers, 12308200 parameters, 0 gradients, 16.1 GFLOPs\n",
      "\n",
      "\u001b[34m\u001b[1mPyTorch:\u001b[0m starting from runs/fold_4.pt with output shape (1, 102000, 6) (24.3 MB)\n",
      "\n",
      "\u001b[34m\u001b[1mONNX:\u001b[0m starting export with onnx 1.12.0...\n",
      "\u001b[34m\u001b[1mONNX:\u001b[0m export success âœ… 5.1s, saved as runs/fold_4.onnx (24.3 MB)\n",
      "\n",
      "\u001b[34m\u001b[1mTensorRT:\u001b[0m starting export with TensorRT 8.4.3.1...\n",
      "[10/14/2022-22:47:01] [TRT] [I] [MemUsageChange] Init CUDA: CPU +303, GPU +0, now: CPU 2385, GPU 8600 (MiB)\n",
      "[10/14/2022-22:47:03] [TRT] [I] [MemUsageChange] Init builder kernel library: CPU +207, GPU +68, now: CPU 2611, GPU 8668 (MiB)\n",
      "/media/salen/ROG2T/NIPS/Train-Labeled/yolov5_mod/export.py:270: DeprecationWarning: Use set_memory_pool_limit instead.\n",
      "  config.max_workspace_size = workspace * 1 << 30\n",
      "[10/14/2022-22:47:03] [TRT] [I] ----------------------------------------------------------------\n",
      "[10/14/2022-22:47:03] [TRT] [I] Input filename:   runs/fold_4.onnx\n",
      "[10/14/2022-22:47:03] [TRT] [I] ONNX IR version:  0.0.7\n",
      "[10/14/2022-22:47:03] [TRT] [I] Opset version:    12\n",
      "[10/14/2022-22:47:03] [TRT] [I] Producer name:    pytorch\n",
      "[10/14/2022-22:47:03] [TRT] [I] Producer version: 1.12.1\n",
      "[10/14/2022-22:47:03] [TRT] [I] Domain:           \n",
      "[10/14/2022-22:47:03] [TRT] [I] Model version:    0\n",
      "[10/14/2022-22:47:03] [TRT] [I] Doc string:       \n",
      "[10/14/2022-22:47:03] [TRT] [I] ----------------------------------------------------------------\n",
      "[10/14/2022-22:47:03] [TRT] [W] onnx2trt_utils.cpp:369: Your ONNX model has been generated with INT64 weights, while TensorRT does not natively support INT64. Attempting to cast down to INT32.\n",
      "\u001b[34m\u001b[1mTensorRT:\u001b[0m input \"images\" with shape(1, 3, 1280, 1280) DataType.HALF\n",
      "\u001b[34m\u001b[1mTensorRT:\u001b[0m output \"output0\" with shape(1, 102000, 6) DataType.HALF\n",
      "\u001b[34m\u001b[1mTensorRT:\u001b[0m building FP16 engine as runs/fold_4.engine\n",
      "/media/salen/ROG2T/NIPS/Train-Labeled/yolov5_mod/export.py:297: DeprecationWarning: Use build_serialized_network instead.\n",
      "  with builder.build_engine(network, config) as engine, open(f, 'wb') as t:\n",
      "[10/14/2022-22:47:04] [TRT] [I] [MemUsageChange] Init cuBLAS/cuBLASLt: CPU +0, GPU +8, now: CPU 2640, GPU 8676 (MiB)\n",
      "[10/14/2022-22:47:04] [TRT] [I] [MemUsageChange] Init cuDNN: CPU +0, GPU +8, now: CPU 2640, GPU 8684 (MiB)\n",
      "[10/14/2022-22:47:04] [TRT] [W] TensorRT was linked against cuDNN 8.4.1 but loaded cuDNN 8.3.2\n",
      "[10/14/2022-22:47:04] [TRT] [I] Local timing cache in use. Profiling results in this builder pass will not be stored.\n",
      "[10/14/2022-22:51:33] [TRT] [I] Some tactics do not have sufficient workspace memory to run. Increasing workspace size will enable more tactics, please check verbose output for requested sizes.\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "File \u001b[0;32m~/miniconda3/envs/torch/lib/python3.9/site-packages/IPython/utils/_process_posix.py:153\u001b[0m, in \u001b[0;36mProcessHandler.system\u001b[0;34m(self, cmd)\u001b[0m\n\u001b[1;32m    150\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[1;32m    151\u001b[0m     \u001b[38;5;66;03m# res is the index of the pattern that caused the match, so we\u001b[39;00m\n\u001b[1;32m    152\u001b[0m     \u001b[38;5;66;03m# know whether we've finished (if we matched EOF) or not\u001b[39;00m\n\u001b[0;32m--> 153\u001b[0m     res_idx \u001b[38;5;241m=\u001b[39m \u001b[43mchild\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mexpect_list\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpatterns\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread_timeout\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    154\u001b[0m     \u001b[38;5;28mprint\u001b[39m(child\u001b[38;5;241m.\u001b[39mbefore[out_size:]\u001b[38;5;241m.\u001b[39mdecode(enc, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mreplace\u001b[39m\u001b[38;5;124m'\u001b[39m), end\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "File \u001b[0;32m~/miniconda3/envs/torch/lib/python3.9/site-packages/pexpect/spawnbase.py:372\u001b[0m, in \u001b[0;36mSpawnBase.expect_list\u001b[0;34m(self, pattern_list, timeout, searchwindowsize, async_, **kw)\u001b[0m\n\u001b[1;32m    371\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 372\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mexp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mexpect_loop\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/torch/lib/python3.9/site-packages/pexpect/expect.py:169\u001b[0m, in \u001b[0;36mExpecter.expect_loop\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    168\u001b[0m \u001b[38;5;66;03m# Still have time left, so read more data\u001b[39;00m\n\u001b[0;32m--> 169\u001b[0m incoming \u001b[38;5;241m=\u001b[39m \u001b[43mspawn\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread_nonblocking\u001b[49m\u001b[43m(\u001b[49m\u001b[43mspawn\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmaxread\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    170\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mspawn\u001b[38;5;241m.\u001b[39mdelayafterread \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "File \u001b[0;32m~/miniconda3/envs/torch/lib/python3.9/site-packages/pexpect/pty_spawn.py:500\u001b[0m, in \u001b[0;36mspawn.read_nonblocking\u001b[0;34m(self, size, timeout)\u001b[0m\n\u001b[1;32m    497\u001b[0m \u001b[38;5;66;03m# Because of the select(0) check above, we know that no data\u001b[39;00m\n\u001b[1;32m    498\u001b[0m \u001b[38;5;66;03m# is available right now. But if a non-zero timeout is given\u001b[39;00m\n\u001b[1;32m    499\u001b[0m \u001b[38;5;66;03m# (possibly timeout=None), we call select() with a timeout.\u001b[39;00m\n\u001b[0;32m--> 500\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (timeout \u001b[38;5;241m!=\u001b[39m \u001b[38;5;241m0\u001b[39m) \u001b[38;5;129;01mand\u001b[39;00m \u001b[43mselect\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m)\u001b[49m:\n\u001b[1;32m    501\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28msuper\u001b[39m(spawn, \u001b[38;5;28mself\u001b[39m)\u001b[38;5;241m.\u001b[39mread_nonblocking(size)\n",
      "File \u001b[0;32m~/miniconda3/envs/torch/lib/python3.9/site-packages/pexpect/pty_spawn.py:450\u001b[0m, in \u001b[0;36mspawn.read_nonblocking.<locals>.select\u001b[0;34m(timeout)\u001b[0m\n\u001b[1;32m    449\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mselect\u001b[39m(timeout):\n\u001b[0;32m--> 450\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mselect_ignore_interrupts\u001b[49m\u001b[43m(\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mchild_fd\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m[\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m[\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m)\u001b[49m[\u001b[38;5;241m0\u001b[39m]\n",
      "File \u001b[0;32m~/miniconda3/envs/torch/lib/python3.9/site-packages/pexpect/utils.py:143\u001b[0m, in \u001b[0;36mselect_ignore_interrupts\u001b[0;34m(iwtd, owtd, ewtd, timeout)\u001b[0m\n\u001b[1;32m    142\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 143\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mselect\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mselect\u001b[49m\u001b[43m(\u001b[49m\u001b[43miwtd\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mowtd\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mewtd\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    144\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mInterruptedError\u001b[39;00m:\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: ",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "File \u001b[0;32m<timed eval>:1\u001b[0m, in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n",
      "File \u001b[0;32m~/miniconda3/envs/torch/lib/python3.9/site-packages/ipykernel/zmqshell.py:633\u001b[0m, in \u001b[0;36mZMQInteractiveShell.system_piped\u001b[0;34m(self, cmd)\u001b[0m\n\u001b[1;32m    631\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39muser_ns[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m_exit_code\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m system(cmd)\n\u001b[1;32m    632\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 633\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39muser_ns[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m_exit_code\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[43msystem\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mvar_expand\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcmd\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdepth\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/torch/lib/python3.9/site-packages/IPython/utils/_process_posix.py:177\u001b[0m, in \u001b[0;36mProcessHandler.system\u001b[0;34m(self, cmd)\u001b[0m\n\u001b[1;32m    174\u001b[0m         \u001b[38;5;28;01mpass\u001b[39;00m\n\u001b[1;32m    175\u001b[0m     \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[1;32m    176\u001b[0m         \u001b[38;5;66;03m# Ensure the subprocess really is terminated\u001b[39;00m\n\u001b[0;32m--> 177\u001b[0m         \u001b[43mchild\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mterminate\u001b[49m\u001b[43m(\u001b[49m\u001b[43mforce\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[1;32m    178\u001b[0m \u001b[38;5;66;03m# add isalive check, to ensure exitstatus is set:\u001b[39;00m\n\u001b[1;32m    179\u001b[0m child\u001b[38;5;241m.\u001b[39misalive()\n",
      "File \u001b[0;32m~/miniconda3/envs/torch/lib/python3.9/site-packages/pexpect/pty_spawn.py:650\u001b[0m, in \u001b[0;36mspawn.terminate\u001b[0;34m(self, force)\u001b[0m\n\u001b[1;32m    648\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[1;32m    649\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mkill(signal\u001b[38;5;241m.\u001b[39mSIGINT)\n\u001b[0;32m--> 650\u001b[0m \u001b[43mtime\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msleep\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdelayafterterminate\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    651\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39misalive():\n\u001b[1;32m    652\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "%%time\n",
    "!python export.py --img  1280 --weights runs/fold_4.pt runs/fold_3.pt runs/fold_2.pt runs/fold_1.pt runs/fold_0.pt  --half --iou-thres 0.5 --conf-thres=0.4 --device 0 --include engine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "ed2b0291-9f7a-496a-8e78-9bfd6eb97b2a",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mcustom_det: \u001b[0mweights=['runs/fold_4.pt', 'runs/fold_3.pt', 'runs/fold_2.pt', 'runs/fold_1.pt', 'runs/fold_0.pt'], source=patched_cache, data=data/coco128.yaml, imgsz=[1280, 1280], conf_thres=0.4, iou_thres=0.5, max_det=20000, device=, view_img=False, save_txt=True, save_conf=True, save_crop=False, nosave=True, classes=None, agnostic_nms=False, augment=False, visualize=False, update=False, project=patched_cache/detect, name=testa, exist_ok=False, line_thickness=1, hide_labels=True, hide_conf=False, half=True, dnn=False, vid_stride=1\n",
      "Patching...\n",
      "YOLO Inferencing...\n",
      "YOLOv5 ðŸš€ v6.2-189-g2f1eb21 Python-3.9.13 torch-1.12.1 CUDA:0 (Quadro RTX 5000, 16125MiB)\n",
      "\n",
      "Fusing layers... \n",
      "Model summary: 206 layers, 12308200 parameters, 0 gradients, 16.1 GFLOPs\n",
      "Fusing layers... \n",
      "Model summary: 206 layers, 12308200 parameters, 0 gradients, 16.1 GFLOPs\n",
      "Fusing layers... \n",
      "Model summary: 206 layers, 12308200 parameters, 0 gradients, 16.1 GFLOPs\n",
      "Fusing layers... \n",
      "Model summary: 206 layers, 12308200 parameters, 0 gradients, 16.1 GFLOPs\n",
      "Fusing layers... \n",
      "Model summary: 206 layers, 12308200 parameters, 0 gradients, 16.1 GFLOPs\n",
      "Ensemble created with ['runs/fold_4.pt', 'runs/fold_3.pt', 'runs/fold_2.pt', 'runs/fold_1.pt', 'runs/fold_0.pt']\n",
      "\n",
      "image 1/15 /media/salen/ROG2T/NIPS/Train-Labeled/yolov5_mod/patched_cache/unlabeled_cell_00001&0&0.png: 1280x1280 20 cells, 78.8ms\n",
      "image 2/15 /media/salen/ROG2T/NIPS/Train-Labeled/yolov5_mod/patched_cache/unlabeled_cell_00001&0&500.png: 1280x1280 29 cells, 80.0ms\n",
      "image 3/15 /media/salen/ROG2T/NIPS/Train-Labeled/yolov5_mod/patched_cache/unlabeled_cell_00001&0&920.png: 1280x1280 40 cells, 71.3ms\n",
      "image 4/15 /media/salen/ROG2T/NIPS/Train-Labeled/yolov5_mod/patched_cache/unlabeled_cell_00001&1000&0.png: 1280x1280 63 cells, 78.8ms\n",
      "image 5/15 /media/salen/ROG2T/NIPS/Train-Labeled/yolov5_mod/patched_cache/unlabeled_cell_00001&1000&500.png: 1280x1280 56 cells, 72.9ms\n",
      "image 6/15 /media/salen/ROG2T/NIPS/Train-Labeled/yolov5_mod/patched_cache/unlabeled_cell_00001&1000&920.png: 1280x1280 51 cells, 66.8ms\n",
      "image 7/15 /media/salen/ROG2T/NIPS/Train-Labeled/yolov5_mod/patched_cache/unlabeled_cell_00001&1500&0.png: 1280x1280 58 cells, 78.3ms\n",
      "image 8/15 /media/salen/ROG2T/NIPS/Train-Labeled/yolov5_mod/patched_cache/unlabeled_cell_00001&1500&500.png: 1280x1280 57 cells, 78.4ms\n",
      "image 9/15 /media/salen/ROG2T/NIPS/Train-Labeled/yolov5_mod/patched_cache/unlabeled_cell_00001&1500&920.png: 1280x1280 45 cells, 80.3ms\n",
      "image 10/15 /media/salen/ROG2T/NIPS/Train-Labeled/yolov5_mod/patched_cache/unlabeled_cell_00001&1560&0.png: 1280x1280 58 cells, 97.5ms\n",
      "image 11/15 /media/salen/ROG2T/NIPS/Train-Labeled/yolov5_mod/patched_cache/unlabeled_cell_00001&1560&500.png: 1280x1280 53 cells, 80.9ms\n",
      "image 12/15 /media/salen/ROG2T/NIPS/Train-Labeled/yolov5_mod/patched_cache/unlabeled_cell_00001&1560&920.png: 1280x1280 44 cells, 78.1ms\n",
      "image 13/15 /media/salen/ROG2T/NIPS/Train-Labeled/yolov5_mod/patched_cache/unlabeled_cell_00001&500&0.png: 1280x1280 46 cells, 76.1ms\n",
      "image 14/15 /media/salen/ROG2T/NIPS/Train-Labeled/yolov5_mod/patched_cache/unlabeled_cell_00001&500&500.png: 1280x1280 41 cells, 85.1ms\n",
      "image 15/15 /media/salen/ROG2T/NIPS/Train-Labeled/yolov5_mod/patched_cache/unlabeled_cell_00001&500&920.png: 1280x1280 51 cells, 62.9ms\n",
      "Speed: 2.0ms pre-process, 77.8ms inference, 10.5ms NMS per image at shape (1, 3, 1280, 1280)\n",
      "Results saved to \u001b[1mpatched_cache/detect/testa\u001b[0m\n",
      "15 labels saved to patched_cache/detect/testa/labels\n",
      "Seg Weithts Loaded.\n",
      "UNet Inferencing and Postprocessing...\n",
      "Patch Inferencing...\n",
      "CPU times: user 470 ms, sys: 128 ms, total: 598 ms\n",
      "Wall time: 22.3 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "!python custom_det.py --img 1280 --source patched_cache --weights runs/fold_4.pt runs/fold_3.pt runs/fold_2.pt runs/fold_1.pt runs/fold_0.pt --name testa --max-det 20000 --half --iou-thres 0.5 --conf-thres=0.4 --save-txt --save-conf --line-thickness 1 --hide-labels --project patched_cache/detect --nosave"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "423733ef-e061-45fa-bd8e-8cbee4bab4c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import albumentations as A\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import timm\n",
    "\n",
    "import segmentation_models_pytorch as smp\n",
    "from torch.cuda.amp import autocast, GradScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b76bcfc8-839b-4e91-b47c-5feccacba299",
   "metadata": {},
   "outputs": [],
   "source": [
    "from ensemble_boxes import weighted_boxes_fusion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "3608611b-26d1-44a0-8def-88781e8fdc04",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tifffile as tif"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "e096439d-8fa7-458e-9a7e-fc0b201f14d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "mean = (0.485, 0.456, 0.406) # RGB\n",
    "std = (0.229, 0.224, 0.225) # RGB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "9702d8d3-7c54-4613-bc60-423ae9912659",
   "metadata": {},
   "outputs": [],
   "source": [
    "albu_transforms = {\n",
    "    'valid' : A.Compose([\n",
    "            A.Resize(224, 224),\n",
    "            A.Normalize(mean, std),\n",
    "    ]),\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "a09e298b-7fff-4933-8205-d5e55ba36ddb",
   "metadata": {},
   "outputs": [],
   "source": [
    "class BboxDataset(torch.utils.data.Dataset):\n",
    "    def __init__(self,\n",
    "                 img,\n",
    "                 boxes,\n",
    "                 mode='train'):\n",
    "        self.img = img\n",
    "        self.boxes = boxes\n",
    "        self.mode = mode\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.boxes)\n",
    "\n",
    "    def __getitem__(self, idx: int):\n",
    "        \n",
    "        shape = self.img.shape\n",
    "        xmin, ymin, xmax, ymax = self.boxes[idx]\n",
    "        xmin, ymin, xmax, ymax = round(xmin*shape[1]), round(ymin*shape[0]), round(xmax*shape[1]), round(ymax*shape[0])\n",
    "        croped = self.img[ymin:ymax, xmin:xmax]\n",
    "        #print(croped.shape)\n",
    "        auged = albu_transforms['valid'](image=croped)\n",
    "        image = torch.from_numpy(auged['image']).permute(2,0,1)\n",
    "\n",
    "        return image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "48ee03b8-6e9a-4039-b32a-3ba659fb65d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "class TimmSED(nn.Module):\n",
    "    def __init__(self, base_model_name: str, pretrained=False, num_classes=24, in_channels=1):\n",
    "        super().__init__()\n",
    "        \n",
    "        #self.bn0 = nn.BatchNorm2d(CFG.n_mels)\n",
    "\n",
    "        #self.encoder = timm.create_model(\n",
    "        #    base_model_name, pretrained=pretrained, in_chans=in_channels, num_classes=num_classes)\n",
    "        self.encoder = smp.Unet(\n",
    "                encoder_name=base_model_name,        # choose encoder, e.g. mobilenet_v2 or efficientnet-b7\n",
    "                encoder_weights=pretrained,     # use `imagenet` pre-trained weights for encoder initialization\n",
    "                in_channels=in_channels,                  # model input channels (1 for gray-scale images, 3 for RGB, etc.)\n",
    "                classes=num_classes,                      # model output channels (number of classes in your dataset)\n",
    "            )\n",
    "        \n",
    "\n",
    "    def forward(self, input_data):\n",
    "        x = input_data \n",
    "        logit = self.encoder(x)\n",
    "\n",
    "        return logit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "e6b29bda-f0ed-499d-aedd-1ebfc9a2554b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loaded\n"
     ]
    }
   ],
   "source": [
    "model = TimmSED(\n",
    "    base_model_name=\"efficientnet-b0\",\n",
    "    pretrained=None,\n",
    "    num_classes=2,\n",
    "    in_channels=3)\n",
    "\n",
    "model.to('cuda')\n",
    "model.load_state_dict(torch.load('../fold-0.bin'))\n",
    "model.eval()\n",
    "print('loaded')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "b0df03d4-bfc7-4173-a16c-9c2b1e8149ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "def bbox_inference(image, boxes):\n",
    "    ds = BboxDataset(image, boxes)\n",
    "    dl = torch.utils.data.DataLoader(\n",
    "            ds, batch_size=32, num_workers=12, pin_memory=True, shuffle=False, drop_last=False\n",
    "        )\n",
    "    results = []\n",
    "    for data in tqdm(dl):\n",
    "        with torch.no_grad():\n",
    "            with autocast():\n",
    "                seg_results = torch.sigmoid(model(data.to('cuda'))[:,1])\n",
    "                #print(seg_results.shape)\n",
    "                final_result = (seg_results>0.5).int().to('cpu').numpy().tolist()\n",
    "        results += final_result\n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "59fde11e-e94b-4e80-ae54-5724a3604e19",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "glob.glob('patched_cache/detect/testa/labels/{}&*&*.txt'.format(img_path.split('/')[-1].split('.')[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "375c4a42-6363-4885-b7ff-98d8a7825bfe",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "765a1189-1141-485d-89b6-e41f96135a86",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "patched\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  1.40it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "patched\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:01<00:00,  3.88it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "unpatched\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3/3 [00:00<00:00,  3.19it/s]\n"
     ]
    }
   ],
   "source": [
    "if not os.path.isdir('./outputs'):\n",
    "    os.makedirs('./outputs')\n",
    "else:\n",
    "    shutil.rmtree('./outputs', ignore_errors=True)\n",
    "    os.makedirs('./outputs')\n",
    "\n",
    "for img_path in all_images:\n",
    "    raw_image = cv2.imread(img_path)\n",
    "    shape = raw_image.shape\n",
    "    if min(shape[:2]) > 1000:\n",
    "        print('patched')\n",
    "        det_files = glob.glob('patched_cache/detect/testa/labels/{}&*&*.txt'.format(img_path.split('/')[-1].split('.')[0]))\n",
    "        if len(det_files) > 0:\n",
    "            box_set = []\n",
    "            conf_set = []\n",
    "            cls_set = []\n",
    "            for file in det_files:\n",
    "                boxes = []\n",
    "                confs = []\n",
    "                split = file.split('/')[-1].split('&')\n",
    "                leftx, topy = int(split[-2])/shape[1], int(split[-1][:-4])/shape[0]\n",
    "                with open(file, 'r') as f:\n",
    "                    data = f.readlines()\n",
    "                    f.close()\n",
    "                for res in data:\n",
    "                    cls, x, y, w, h, conf = res.split(' ')\n",
    "                    x, y, w, h, conf = float(x), float(y), float(w), float(h), float(conf)\n",
    "\n",
    "                    xmin, ymin, xmax, ymax = (x-0.5*w)*1000, (y-0.5*h)*1000, (x+0.5*w)*1000, (y+0.5*h)*1000\n",
    "\n",
    "                    if min(xmin, ymin, xmax, ymax) > 5 and max(xmin, ymin, xmax, ymax) < 995:\n",
    "                        #print((xmin, ymin, xmax, ymax), min(xmin, ymin, xmax, ymax), max(xmin, ymin, xmax, ymax))\n",
    "                        xmin, ymin, xmax, ymax = xmin/shape[1]+leftx, ymin/shape[0]+topy, xmax/shape[1]+leftx, ymax/shape[0]+topy\n",
    "                        boxes.append([xmin, ymin, xmax, ymax])\n",
    "                        confs.append(conf)\n",
    "                        #print(1)\n",
    "                        #continue\n",
    "\n",
    "                box_set.append(boxes)\n",
    "                conf_set.append(confs)\n",
    "                cls_set.append([0]*len(confs))\n",
    "\n",
    "\n",
    "            boxes, confs, _ = weighted_boxes_fusion(box_set, conf_set, cls_set)\n",
    "            #boxes = []\n",
    "            #for box in wbf_boxes:\n",
    "            #    xmin, ymin, xmax, ymax = box\n",
    "            #    xmin, ymin, xmax, ymax = round(xmin*shape[1]), round(ymin*shape[0]), round(xmax*shape[1]), round(ymax*shape[0])\n",
    "                #print(min((xmax-xmin)*shape[1], (ymax-ymin)*shape[0]))\n",
    "                #if min(xmax-xmin, ymax-ymin) > 2:\n",
    "                #    boxes.append(box)\n",
    "                #else:\n",
    "                #    print('zero')\n",
    "        #break\n",
    "    else:\n",
    "        print('unpatched')\n",
    "        file = 'patched_cache/detect/testa/labels/{}$0.txt'.format(img_path.split('/')[-1].split('.')[0])\n",
    "        if os.path.isfile(file):\n",
    "            #print('No Patch')\n",
    "            boxes = []\n",
    "            confs = []\n",
    "            with open(file, 'r') as f:\n",
    "                data = f.readlines()\n",
    "                f.close()\n",
    "            for res in data:\n",
    "                cls, x, y, w, h, conf = res.split(' ')\n",
    "                x, y, w, h, conf = float(x), float(y), float(w), float(h), float(conf)\n",
    "                xmin, ymin, xmax, ymax = (x-0.5*w), (y-0.5*h), (x+0.5*w), (y+0.5*h)\n",
    "                if min((xmax-xmin)*shape[1], (ymax-ymin)*shape[0]) > 2:\n",
    "                    boxes.append([xmin, ymin, xmax, ymax])\n",
    "                    confs.append(conf)\n",
    "\n",
    "    base = np.zeros((shape[0], shape[1]), dtype='uint16')\n",
    "    if boxes is not None:\n",
    "        if len(boxes) > 65000:\n",
    "            base = np.zeros((shape[0], shape[1]), dtype='uint32')\n",
    "        masks = bbox_inference(raw_image, boxes)\n",
    "\n",
    "        cell_count = 1\n",
    "        for box, mask in zip(boxes, masks):\n",
    "            xmin, ymin, xmax, ymax = box\n",
    "            xmin, ymin, xmax, ymax = round(xmin*shape[1]), round(ymin*shape[0]), round(xmax*shape[1]), round(ymax*shape[0])\n",
    "            mask = cv2.resize(np.array(mask), (xmax-xmin, ymax-ymin), interpolation=cv2.INTER_NEAREST).astype(bool)\n",
    "\n",
    "            base[ymin:ymax, xmin:xmax][mask] = cell_count\n",
    "            cell_count+=1\n",
    "\n",
    "    #\n",
    "    #raw_image = np.stack([base*0.5]*3, -1) + raw_image*0.5\n",
    "    #cv2.imwrite('vis/{}.png'.format(idx), raw_image)\n",
    "\n",
    "        #os.removedirs('./outputs')\n",
    "    tif.imwrite('./outputs/{}_label.tiff'.format(img_path.split('/')[-1].split('.')[0]), base, compression='zlib')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8202f8e0-cf21-4c87-ade6-6ed130add9cd",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
